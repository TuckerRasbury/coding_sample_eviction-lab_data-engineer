{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0RgClnReAVXQ8K6nSog8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuckerRasbury/coding_sample_eviction-lab_data-engineer/blob/main/Eviction_Lab_Data_Engineer_Coding_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Sample - Data Pipeline for Evictions Filings\n",
        "#### _Submission of Candidate Coding Sample for the role of Data Engineer at The Eviction Lab of Princeton University_\n"
      ],
      "metadata": {
        "id": "FWOBs4GUudNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Prompt\n",
        "---\n",
        "\n",
        "In order to apply to the Data Engineer role at the Eviction Lab, I am spinning up a concise data pipeline to meet the fourth criteria laid out in the listing.\n",
        "\n",
        "_\"Applicants should submit a dossier including... (4) a coding sample or data product that speaks to applicant’s experience with relevant tasks\"_\n",
        "\n",
        "## Tasks Required of the Data Engineer\n",
        "---\n",
        "\n",
        "Here is an excerpt from the listing including what will be required of the Data Engineer for context.\n",
        "\n",
        "_\"The responsibilities of the position are to lead the development of a data construction pipeline for processing large-scale administrative records. This would involve writing code to create new data products (e.g., geocoding addresses, cleaning names, combining multiple sources of data) in a reproducible way; writing tests to assess the quality of the data products created by the pipeline; writing tests to assess the speed of the pipeline; optimizing the code to improve quality and speed; cleaning and reformatting incoming datasets to conform to the pipeline; running the pipeline using these datasets; and identifying and fixing bugs, among other tasks. The datasets used are very large and require the use of remote computing clusters. Applicants with experience using very large datasets and optimizing code to run efficiently are preferred.\"_"
      ],
      "metadata": {
        "id": "aYydTlIivquK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Script\n",
        "---\n",
        "In order to provide a coding sample to demonstrate some of the pre-requisite skills for this opening, herein I will spin up a light weight data pipeline. I would ideally like to gather more data, but in light of the U.S. Government Accountability Office's research  on eviction data availability being limited, I am going to leverage the csv download available datasets above [3].\n",
        "\n",
        "### Part 1 - Ingesting CSV/Excel\n",
        "For this part, I obtained data from the Legal Services Corporation (LSC) [2] and Zillow's publicly available datasets [3]. These datasets were downloadable as CSVs on their websites, stored to Github, and then ingested here. The method used below to ingest these datasets can easily be applied to Excel files as well.\n",
        "\n",
        "\n",
        "#### Explaining the data collected\n",
        "The first dataset from LSC is from their evictions tracker and according to them \"provides access to multi-year trend data on eviction filings for 1,250 counties and municipalities in 30 states and territories across the United States.\" The second datasets from zillow represent their ZHVI and ZORI variables at the state and county levels. Those variables are explained below.\n",
        "\n",
        "- Zillow Home Value Index (ZHVI): A measure of the typical home value and market changes across a given region and housing type.\n",
        "- Zillow Observed Rent Index (ZORI): A smoothed measure of the typical observed market rate rent across a given region\n",
        "\n",
        "\n",
        "\n",
        "#------------[WIP]------------\n",
        "\n",
        "\n",
        "### Part 2 - Ingesting from API\n",
        "For this portion, I searched for an API option. The option that I went with was the U.S. Census related one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------------[WIP]------------\n",
        "\n",
        "\n",
        "\n",
        "Data Sources and Appendix\n",
        "---\n",
        "1. Appendix - [Government Accountability Office - Evictions: National Data Are Limited and Challenging to Collect](https://www.gao.gov/products/gao-24-106637)\n",
        "\n",
        "2. Data - [Civil Court Data Initiative. Legal Services Corporation, 2022.(accessed May 16, 2025)](https://civilcourtdata.lsc.gov/data/eviction)\n",
        "\n",
        "3. Data - [Rental Data. Zillow. (accessed May 16, 2025)](https://www.zillow.com/research/data/)\n",
        "\n"
      ],
      "metadata": {
        "id": "DzU86y16xkww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Work"
      ],
      "metadata": {
        "id": "58oVHdO8f51_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Establishing Libraries\n",
        "import pandas as pd # used for data manipulation\n",
        "import os\n",
        "import requests # used for API Calls\n",
        "import time # used for creating artificial delays to assist with data grabs"
      ],
      "metadata": {
        "id": "P9HysbHl4QWE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Ingesting CSV/Excel"
      ],
      "metadata": {
        "id": "XBOUetWP4D7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingesting - CSV - Zillow and Legal Services Corp (LSC)"
      ],
      "metadata": {
        "id": "kx1yvNMzA13o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i6wV1cl-uCmZ"
      },
      "outputs": [],
      "source": [
        "# Importing Datasets\n",
        "\n",
        "## Legal Services Corporation - Civil Court Data Initiative\n",
        "### Weekly County Data\n",
        "lsc_weekly_county_url = 'https://raw.githubusercontent.com/TuckerRasbury/coding_sample_eviction-lab_data-engineer/main/data/weekly_county_data_download.csv'\n",
        "lsc_weekly_county__df = pd.read_csv(lsc_weekly_county_url)\n",
        "\n",
        "### Weekly State Data\n",
        "lsc_weekly_state_url = 'https://raw.githubusercontent.com/TuckerRasbury/coding_sample_eviction-lab_data-engineer/main/data/weekly_state_data_download.csv'\n",
        "lsc_weekly_state_df = pd.read_csv(lsc_weekly_state_url)\n",
        "\n",
        "# Add a small delay before the next request\n",
        "time.sleep(2)\n",
        "\n",
        "## Zillow House Value Data\n",
        "## Zillow Home Value Index (ZHVI): A measure of the typical home value and market\n",
        "## changes across a given region and housing type.\n",
        "\n",
        "\n",
        "### Publicly Available Housing Data - County\n",
        "zillow_county_url = 'https://raw.githubusercontent.com/TuckerRasbury/coding_sample_eviction-lab_data-engineer/main/data/County_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'\n",
        "zillow_county_df = pd.read_csv(zillow_county_url)\n",
        "\n",
        "### Publicly Available Housing Data - State\n",
        "zillow_state_url = 'https://raw.githubusercontent.com/TuckerRasbury/coding_sample_eviction-lab_data-engineer/main/data/State_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'\n",
        "zillow_state_df = pd.read_csv(zillow_state_url)\n",
        "\n",
        "# Add a small delay before the next request\n",
        "time.sleep(2)\n",
        "\n",
        "## Zillow Rental Price Data - County\n",
        "## Zillow Observed Rent Index (ZORI): A smoothed measure of the typical observed\n",
        "## market rate rent across a given region\n",
        "\n",
        "### Publicly Available Rental Data - County\n",
        "zillow_county_rental_url = 'https://raw.githubusercontent.com/TuckerRasbury/coding_sample_eviction-lab_data-engineer/main/data/County_zori_uc_sfrcondomfr_sm_month.csv'\n",
        "zillow_county_rental_df = pd.read_csv(zillow_state_url)\n",
        "\n",
        "# Add a small delay before the next request\n",
        "time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of designing tests to assess data shape (rows, columns)\n",
        "\n",
        "print(\" LSC shape:\", lsc_weekly_county__df.shape)\n",
        "print(\" Zillow shape:\", zillow_county_rental_df.shape)"
      ],
      "metadata": {
        "id": "Cp13Ij72maUR",
        "outputId": "92278b00-d860-4004-e662-96a5bd9625a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LSC shape: (252740, 4)\n",
            " Zillow shape: (51, 309)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Ingesting - API - U.S. Census"
      ],
      "metadata": {
        "id": "bLCXEeBBlfLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a working API Key\n",
        "\n",
        "CENSUS_API_KEY = '86d117578634c16e49a8242b3a91ee1ee93e7834'\n",
        "\n",
        "## For PROD, we would do this with some level of secret script seperately stored in the codebase.\n",
        "## For this proof of concept, this is acceptable for now, but will need to be deleted/updated later."
      ],
      "metadata": {
        "id": "QYh3xkz9fFpd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab Median Income for All California Counties\n",
        "## The data I'm targeting herein is the ACS (American Community Survey) 5-year estimates (poverty, rent burden, etc.)\n",
        "\n",
        "\n",
        "# URL and parameters for California counties only\n",
        "url = \"https://api.census.gov/data/2021/acs/acs5\"\n",
        "params = {\n",
        "    \"get\": \"NAME,B19013_001E\",\n",
        "    \"for\": \"county:*\",\n",
        "    \"in\": \"state:06\",  # California's FIPS code is 06\n",
        "    \"key\": CENSUS_API_KEY\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.get(url, params=params, timeout=15)\n",
        "    response.raise_for_status()  # Raises an error if needed\n",
        "except requests.exceptions.Timeout:\n",
        "    print(\"The request to the Census API timed out. Please try again later.\")\n",
        "    response = None\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"API request failed: {e}\")\n",
        "    response = None\n",
        "\n",
        "# Process the response\n",
        "if response:\n",
        "    data = response.json()\n",
        "    df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    df.rename(columns={'B19013_001E': 'median_income'}, inplace=True)\n",
        "    df['median_income'] = pd.to_numeric(df['median_income'], errors='coerce')\n",
        "    df['county_fips'] = df['state'] + df['county']\n",
        "\n",
        "    print(df.head())\n",
        "    print(\"✅ Loaded counties:\", df.shape[0])\n"
      ],
      "metadata": {
        "id": "CJ2BTVT9fFW-",
        "outputId": "6cf175f9-ce85-45da-9647-de4ec79a2c28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The request to the Census API timed out. Please try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLZxiyaCsRRx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y66intTDsRCJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgfEKJeKsQuT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Designing Tests to Assess Data Quality and Shape"
      ],
      "metadata": {
        "id": "Oy_dYOOCXFJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmxR-QW3ckGD"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}